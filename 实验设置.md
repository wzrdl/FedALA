下面给你一套**可直接执行**、并且在因果上尽量“干净”的完整实验方案：包含

1. **完整实验设计思路（为什么这样设计、每组回答什么机制问题）**
2. **完整实验设计总表（主实验 + 机制测量 Probe）**
3. **完整 config（Base + 每个实验的 override）**
4. **你跑完必须产出的关键图/指标清单（用来写结论）**

---

## 1) 实验设计思路（完整、闭环、可归因）

### 研究目标

解释 **personalization 与 aggregation 如何相互影响 forgetting**，而不是“有没有 forgetting”。

### 关键机制链

一轮联邦更新的闭环：

[
G^t \xrightarrow{\text{personalization}} P_i^t \xrightarrow{\text{local SGD}} L_i^t \xrightarrow{\text{upload}} \text{FedAvg} \to G^{t+1}
]

你要回答两件事：

* **(A) Personalization → Aggregation → Global forgetting**
  personalization 改变 local SGD 的起点，从而改变上传更新集合 ({U_i^t = L_i^t - G^t})，进而改变聚合冲击 (\Delta^{Agg})。

* **(B) Aggregation → Personalization → Local forgetting**
  聚合产生的漂移（(G^{t+1}-G^t)）影响下一轮 personalization 的输入，改变后续 local 轨迹与旧任务保持性。

### 为什么用「关 personalization + 冻结子空间 + Probe」这套组合

* **关 personalization（P=G）**：提供最干净的反事实“有/无 personalization”对照（总效应）。
* **冻结（Freeze-P / Freeze-S）**：不改 FedAvg、不改上传，只改变 local SGD 的可更新子空间，能定位“哪些子空间更新回流导致聚合遗忘”。
* **Probe（同轮同 client 从 (G^t) vs (P_i^t) 短跑）**：直接测 personalization 如何改变 local SGD 更新方向/子空间/风险（机制证据强）。
* 统一用 **progress/accuracy-matched** 对齐，避免冻结带来的“学不动所以不忘”的伪结论。

---

## 2) 完整实验设计总表

### 2.1 主实验（4 组训练轨迹）

> 都是完整 PFCL/FedALA 闭环：每轮 broadcast → personalization → local train → upload (L) → FedAvg → next global

| ID    | 实验名                  | personalization                    | LocalTrain 可更新参数 | 聚合/上传         | 主要回答的机制问题                                                       | 关键判据（跑完你要看什么）                                        |
| ----- | -------------------- | ---------------------------------- | ---------------- | ------------- | --------------------------------------------------------------- | ---------------------------------------------------- |
| **A** | Full-FedALA（基线）      | 正常 FedALA（ALA）                     | **S+P 都更新**      | 上传 (L)，FedAvg | 真实闭环下 forgetting 与 shock 形态                                     | (\Delta^{Agg}) 是否在切换窗口负尖峰？(|U_P|) 是否暴涨？              |
| **B** | No-Pers（P=G）         | 关闭 personalization（直接 (P_i^t=G^t)） | S+P 都更新          | 上传 (L)，FedAvg | personalization 的**总效应**：它到底缓解还是加剧 global/local forgetting？     | 与 A 比：(\Delta^{Agg})、旧任务曲线、(\Delta^{Pers})（修复能力）如何变化 |
| **C** | Freeze-P（冻结个性化承载子空间） | 正常 FedALA（ALA）                     | **只更新 S，冻结 P**   | 上传 (L)，FedAvg | personalization 影响 aggregation forgetting 是否主要通过 **P 子空间回流冲突**？ | 若 C 显著减轻 (\Delta^{Agg}) 负尖峰且压低 (|U_P|) → 支持该机制       |
| **D** | Freeze-S（参数量匹配反对照）   | 正常 FedALA（ALA）                     | **只更新 P，冻结 S**   | 上传 (L)，FedAvg | 排除“冻结万能”；定位冲突更偏 S 还是 P                                          | 若 D 无法像 C 一样改善，且 (|U_P|) 仍大 → 强化 C 的因果解释             |

> 说明：

* **P 子空间**＝你定义的“个性化承载层”（例如 FedALA 作用的高层/最后 p 层）。
* **S 子空间**＝其余共享层（backbone/低层）。
* 冻结的目的不是追求最好精度，而是提供机制因果证据；报告必须做 progress-matched。

---

### 2.2 机制测量（Probe：不改变训练，只做诊断）

| ID     | 名称                                  | 做什么                                                                           | 频率/范围                                   | 目的                                         | 产出                                                            |
| ------ | ----------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------- | ------------------------------------------ | ------------------------------------------------------------- |
| **P1** | Local-SGD Probe（G-start vs P-start） | 在同一轮、同一 client、同一 batch/seed 下：从 (G^t) 与 (P_i^t) 各跑 **m 步**本地 SGD（不上传，不影响主训练） | **只在任务切换后的前 K 轮**；每轮抽样少量 clients（如 5 个） | 直接测 personalization 如何改变 local SGD 更新结构/风险 | (U^{G}) vs (U^{P}) 的：(|U_P|)/(|U_S|)、方向冲突、top-eigen 投影差异、风险差异 |

---

## 3) 实验设置与记录内容（你必须统一）

### 3.1 任务训练与切换（推荐标准设置）

* 任务数：`T`（例如 5）
* 每任务联邦轮数：`R`（例如 20 或 50）
* 每轮参与客户端比例：`C`（例如 0.2 或固定数量）
* 本地训练：`local_epochs`（例如 1/5）或 `local_steps`
* 任务切换：训练完 task j 的 R 轮后直接切到 task j+1，模型与优化器状态**不重置**（除非你显式声明做 reset 实验）

### 3.2 必须记录的核心量（用于机制归因）

**（1）聚合冲击：**

* (\Delta^{Agg}_k(t) = a(G^{t+1},k)-a(G^t,k))（旧任务 k 或旧任务均值）

**（2）上传更新结构：**

* (U_i^t = L_i^t - G^t)
* (|U_i^t|)、(|U_{i,P}^t|)、(|U_{i,S}^t|)（分子空间）

**（3）personalization 修复量（用于 Aggregation→Personalization 方向）：**

* (\Delta^{Pers}_{i,k}(t) = a(P_i^t,k)-a(G^t,k))

**（4）你指定的理论量（global+client 都要）**

* `lambda_max(G^t,k_old)`，`lambda_max(G^{t+1},k_old)`
* `opt_drift(G^t,k_old)`，`opt_drift(G^{t+1},k_old)`
* client 侧至少对 (L_i^t)（可选 (P_i^t)）：`lambda_max(L_i^t,k_old)`、`opt_drift(L_i^t,k_old)`

> 强制要求：固定 BN 策略、固定 client sampling seed、固定数据顺序（或记录下来可复现），否则机制图会抖得很难解释。

---

## 4) 完整 config（Base + override）

下面用 YAML 风格给你一个可落地的配置体系：**base.yaml** 写公共设置，四个实验只是 override 三个字段：`personalization.enabled`、`freeze.mask`、以及 `probe.enabled`。

### 4.1 base.yaml（所有实验共享）

```yaml
experiment:
  seed: 0
  run_name: "BASE"
  output_dir: "./runs"

task_sequence:
  num_tasks: 5
  rounds_per_task: 20
  switch_mode: "sequential"        # task1 -> task2 -> ... 不中断
  reset_optimizer_on_switch: false # 必须固定，否则混淆
  reset_model_on_switch: false

federated:
  num_clients: 20
  client_fraction: 0.2             # 每轮参与比例
  sampling_seed: 2026              # 固定采样
  aggregator: "fedavg"             # 不变
  upload_object: "local_model"     # 上传 L_i^t（不变）

local_train:
  optimizer: "sgd"
  lr: 0.01
  momentum: 0.9
  weight_decay: 0.0
  batch_size: 64
  local_epochs: 5
  grad_clip_norm: null

personalization:                    # FedALA / ALA
  method: "fedala"
  enabled: true
  ala_layers: "last_p_layers"       # 你代码里实际对应的层集合
  p: "default"                      # 这里不是研究对象，仅保持默认
  s_percent: "default"
  ala_lr: "default"
  ala_steps: "default"

freeze:
  enabled: false
  mask: "none"                      # none / freeze_P / freeze_S
  bn_policy: "freeze_stats"         # 强烈建议固定（或你已有的统一策略）

evaluation:
  eval_every_round: true
  eval_old_tasks: true
  eval_current_task: true
  metrics: ["accuracy", "loss"]
  old_task_agg: "mean"              # old tasks 取平均

mechanism_logging:
  log_update_norms: true
  log_update_subspace_norms: true   # 需要能分解到 P/S 子空间
  log_step_shocks: true             # 记录 ΔAgg
  log_personalization_gain: true    # 记录 ΔPers
  record_clients_per_round: "all_participants"  # 或采样部分也行

theory_metrics:
  lambda_max:
    enabled: true
    method: "power_iter_hvp"
    iters: 20
    batch_size: 256
    fixed_batch_seed: 123
    eval_tasks: "old_tasks_mean"    # 或逐旧任务
  opt_drift:
    enabled: true
    mode: "best_checkpoint_per_task" # 统一定义
    distance: "l2"

probe:                               # 默认关，按实验打开
  enabled: false
  steps: 5                           # m步，越小越便宜
  clients_per_round: 5
  only_window_after_switch_rounds: 3 # K=3
  fixed_seed: 777
  fixed_batch: true
  record: ["U_norm", "U_P_norm", "U_S_norm", "grad_alignment", "top_eig_proj"]
```

---

### 4.2 实验 A：Full-FedALA

```yaml
experiment:
  run_name: "A_Full_FedALA"

personalization:
  enabled: true

freeze:
  enabled: false
  mask: "none"

probe:
  enabled: true   # 强烈建议只在 A/B 开 probe，成本可控
```

### 4.3 实验 B：No-Pers（P=G）

```yaml
experiment:
  run_name: "B_No_Pers"

personalization:
  enabled: false   # 直接 P_i^t = G^t

freeze:
  enabled: false
  mask: "none"

probe:
  enabled: true
```

### 4.4 实验 C：Freeze-P

```yaml
experiment:
  run_name: "C_Freeze_P"

personalization:
  enabled: true

freeze:
  enabled: true
  mask: "freeze_P"  # 冻结个性化承载层（你定义的 P 子空间）

probe:
  enabled: false     # 可选：开也行，但先不开节省成本
```

### 4.5 实验 D：Freeze-S（反对照）

```yaml
experiment:
  run_name: "D_Freeze_S"

personalization:
  enabled: true

freeze:
  enabled: true
  mask: "freeze_S"  # 冻结共享层（S），只让 P 更新；参数量尽量匹配 C

probe:
  enabled: false
```

---

## 5) 跑完应该输出哪些图（最关键的 6 张）

你最终写机制结论基本靠这几张：

1. **Global old-task accuracy vs global_round**（标 task boundary）
2. **Aggregation shock**：(\Delta^{Agg}(t)) vs global_round（切换窗口看负尖峰）
3. **Upload update norms**：(\mathbb E|U|) vs global_round
4. **Subspace norms**：(\mathbb E|U_P|)、(\mathbb E|U_S|) vs global_round
5. **Scatter**：(\Delta^{Agg}(t)) vs (\mathbb E|U_P|)（四组对比，回归线）
6. **理论量对齐**：`lambda_max(G^t)` 与 `opt_drift(G^t)` 在切换窗口是否与 (\Delta^{Agg}) 尖峰同步

> 冻结组必须额外给一张：**progress-matched 曲线**（x=当前任务acc，y=旧任务acc），避免“学不动所以不忘”的质疑。

---

## 6) 你需要我把 “P/S 子空间”怎么落地成代码层名吗？

如果你把你模型结构与 FedALA 代码里“ALA 作用层”的选层逻辑贴一段（比如哪些 module name 被选进 p 层），我可以帮你把：

* `freeze_P` / `freeze_S` 的**精确模块列表**
* P/S 的参数量匹配方案（保证 C 与 D 公平）
* 以及 log 子空间范数的实现方式（按参数前缀聚合）

直接写成可用的配置与伪代码。
